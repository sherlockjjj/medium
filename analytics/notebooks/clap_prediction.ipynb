{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1dd9c67a9a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# utils import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_word_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# sklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/medium/analytics/notebooks/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from .. preprocess import (word_tokenize,\n\u001b[0m\u001b[1;32m      3\u001b[0m                            \u001b[0mget_stopwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mget_unusual_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            tokenizer)\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# main import\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# analytics import\n",
    "sys.path.append('..')\n",
    "from preprocess import MediumBlogPost\n",
    "\n",
    "# utils import\n",
    "from utils import parse_date, get_word_count\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# visualization imports\n",
    "import seaborn.apionly as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "files = ['data-science.jl', 'startup.jl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(os.environ['RAW_DATA_PATH'], file_name)\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            # get raw data\n",
    "            row = MediumBlogPost(**json.loads(line)).to_frame()\n",
    "            dfs.append(row)\n",
    "\n",
    "df = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>author_url</th>\n",
       "      <th>headings</th>\n",
       "      <th>contents</th>\n",
       "      <th>mins_read</th>\n",
       "      <th>claps</th>\n",
       "      <th>lang</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25019</th>\n",
       "      <td>13 Self-Destructive Habits of Unhappy and Unsu...</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>Larry Kim</td>\n",
       "      <td>https://medium.com/marketing-and-entrepreneurs...</td>\n",
       "      <td>https://medium.com/@larrykim</td>\n",
       "      <td>13 Self-Destructive Habits of Unhappy and Unsu...</td>\n",
       "      <td>Stop sabotaging your own best efforts with neg...</td>\n",
       "      <td>6</td>\n",
       "      <td>208</td>\n",
       "      <td>en</td>\n",
       "      <td>[Self Improvement, Startup, Marketing, Life Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25020</th>\n",
       "      <td>Slack just raised money at $ 7 B valuation, bu...</td>\n",
       "      <td>2018-08-24</td>\n",
       "      <td>ashu garg</td>\n",
       "      <td>https://medium.com/@ashugarg/slack-just-raised...</td>\n",
       "      <td>https://medium.com/@ashugarg</td>\n",
       "      <td></td>\n",
       "      <td>Slack recently raised $ 427 M at a valuation o...</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>en</td>\n",
       "      <td>[Slack, Startup, Microsoft, Google, Unicorns]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title publish_time  \\\n",
       "25019  13 Self-Destructive Habits of Unhappy and Unsu...   2018-08-24   \n",
       "25020  Slack just raised money at $ 7 B valuation, bu...   2018-08-24   \n",
       "\n",
       "          author                                                url  \\\n",
       "25019  Larry Kim  https://medium.com/marketing-and-entrepreneurs...   \n",
       "25020  ashu garg  https://medium.com/@ashugarg/slack-just-raised...   \n",
       "\n",
       "                         author_url  \\\n",
       "25019  https://medium.com/@larrykim   \n",
       "25020  https://medium.com/@ashugarg   \n",
       "\n",
       "                                                headings  \\\n",
       "25019  13 Self-Destructive Habits of Unhappy and Unsu...   \n",
       "25020                                                      \n",
       "\n",
       "                                                contents  mins_read  claps  \\\n",
       "25019  Stop sabotaging your own best efforts with neg...          6    208   \n",
       "25020  Slack recently raised $ 427 M at a valuation o...          3     13   \n",
       "\n",
       "      lang                                               tags  \n",
       "25019   en  [Self Improvement, Startup, Marketing, Life Le...  \n",
       "25020   en      [Slack, Startup, Microsoft, Google, Unicorns]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6901, 10) (1726, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('claps', axis=1),\n",
    "    df.claps,\n",
    "    test_size=0.2,\n",
    "    random_state=99)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on previous EDA, we think the following features are sensible for predicting claps\n",
    "1. year, month, day\n",
    "2. title word count, stop word count, unusual word count\n",
    "3. headings word count, stop word count, unusual word count\n",
    "4. contents sentence count, contents word count, stop word count, unusual word count\n",
    "5. author number of blogs, average claps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headings_word_count</th>\n",
       "      <th>headings_stopword_count</th>\n",
       "      <th>headings_unusual_word_count</th>\n",
       "      <th>headings_total_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   headings_word_count  headings_stopword_count  headings_unusual_word_count  \\\n",
       "0                    3                        2                            0   \n",
       "1                    4                        2                            4   \n",
       "2                   21                        7                            6   \n",
       "\n",
       "   headings_total_word_count  \n",
       "0                          5  \n",
       "1                         10  \n",
       "2                         34  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_count(df.headings.iloc[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df.iloc[250].contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
